{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "42adac27d77e1ba5cea6ecf598f935ac",
     "grade": false,
     "grade_id": "Introduction",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "# Required end-of-module assignment: Web crawling and scraping\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will apply the skills learned in this module to extract data from a real-world website using Python.\n",
    "\n",
    "This exercise is designed to strengthen your understanding of:\n",
    "- Writing Python code for data extraction.\n",
    "- Parsing HTML using BeautifulSoup.\n",
    "- Traversing web content using Breadth-First Search (BFS) strategies (as applicable).\n",
    "\n",
    "As you progress, the questions will gradually increase in complexity. Be sure to approach the tasks with a programmer's mindset: break problems into smaller parts, write clean code, and test as you go.\n",
    "\n",
    "> **Important:** Run your code in each cell before submitting. This will help you catch and fix errors early.\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Outcomes Addressed\n",
    "\n",
    "- Implement Breadth-First Search (BFS) for basic web crawling.\n",
    "- Use BeautifulSoup to parse and extract structured data from HTML content.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "863d0225fbcf948274393f973810ef10",
     "grade": false,
     "grade_id": "Index",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "## Index:\n",
    "\n",
    "- [Question 1](#Question-1)\n",
    "- [Question 2](#Question-2)\n",
    "- [Question 3](#Question-3)\n",
    "- [Question 4](#Question-4)\n",
    "- [Question 5](#Question-5)\n",
    "- [Question 6](#Question-6)\n",
    "- [Question 7](#Question-7)\n",
    "- [Question 8](#Question-8)\n",
    "- [Question 9](#Question-9)\n",
    "- [Question 10](#Question-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "68d4dec3c046eb3265854ffa35e99923",
     "grade": false,
     "grade_id": "Assignment_Desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Real-World Scenario\n",
    "\n",
    "Imagine your manager has asked you, the company’s data analyst, to extract and format key information from the **FTSE 100 Index** Wikipedia page. You’ll retrieve relevant data from each table on the page and structure it for analysis.\n",
    "\n",
    "**Target Webpage**: [FTSE 100 Index - Wikipedia](https://en.wikipedia.org/wiki/FTSE_100_Index)\n",
    "\n",
    "Use this page as your data source. View the page and inspect its HTML structure to understand how data is organized in tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80cfed7fd440c86a617aaee2af4f2287",
     "grade": false,
     "grade_id": "cell-40ba1a491528ddbf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "requests = requests.Session()\n",
    "\n",
    "# Set default headers for the session\n",
    "requests.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5af52cac24216fc7db77b3c1044854c",
     "grade": false,
     "grade_id": "Q1_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 1: Retrieve the HTML Code\n",
    "\n",
    "In this task, you'll retrieve the HTML content of the FTSE 100 Index Wikipedia page and parse it using BeautifulSoup.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Import the `requests` library and `BeautifulSoup` from `bs4`.\n",
    "2. Send an HTTP GET request to the following URL:\n",
    "```python\n",
    "    url_footsie = \"https://en.wikipedia.org/wiki/FTSE_100_Index\"\n",
    "```\n",
    "3. Extract the text of the HTML page from the response.\n",
    "4. Use `BeautifulSoup` to parse the HTML text.\n",
    "5. Assign the resulting BeautifulSoup object to a variable named `soup`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4568ccd3f605ae1b16a4ffd7193ecea2",
     "grade": false,
     "grade_id": "Class1_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "url_footsie = \"https://en.wikipedia.org/wiki/FTSE_100_Index\"\n",
    "soup = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "46292cf15b907b3b4a607fb1ae276d3f",
     "grade": true,
     "grade_id": "Class1_Tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7118cfc17f622b4d5ead2f11e6bc05b5",
     "grade": false,
     "grade_id": "Q2_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 2: Locate the `<head>` Tag\n",
    "\n",
    "Before scraping specific data like tables, it's important to understand the structure of the HTML. In this task, you'll examine the page layout and retrieve a specific section using BeautifulSoup.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Open the FTSE Wikipedia page in a browser and **inspect the page source** to understand how the HTML is structured — especially how tables are defined.\n",
    "2. Use the `.find()` method from BeautifulSoup to retrieve the `head` section (`<head>`) of the HTML.\n",
    "3. Assign the result to a variable named `ans2`.\n",
    "\n",
    "\n",
    "**Hint:** Use `soup.find()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "171b718a4ae97524b03e0c76c4279cb8",
     "grade": false,
     "grade_id": "Class2_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dae5c910b8336f6e6f48223e89eebf7e",
     "grade": true,
     "grade_id": "Class2_Tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "45f95c371af253230ceb82be766bf231",
     "grade": false,
     "grade_id": "Q3_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 3: Locate and Count Tables on the Page\n",
    "\n",
    "Your boss has asked you to retrieve specific information from the **FTSE (QFA) Contract Specifications** table. To begin, you need to identify and count all tables on the page to locate the one containing the **\"Contract Size: 10 GBP X Index Points\"** entry.\n",
    "\n",
    "#### Reference\n",
    "You are looking for the table that contains the following value:\n",
    "\n",
    "> **Contract Size: 10 GBP X Index Points**\n",
    "\n",
    "Refer to the image:  \n",
    "<img src=\"images/hk_qc_QFA_image_imp_pcba.png\" alt=\"Contracts Table\" />\n",
    "\n",
    "\n",
    "But before that we need to get all the tables from the page.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Use the `.find_all()` method from BeautifulSoup to extract **all `<table>` elements** from the parsed HTML.\n",
    "2. Assign the list of tables to a variable named `ans3a`.\n",
    "3. Count the number of tables and assign the result to a variable named `ans3b`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "af3584ed9c13d38d3090fb2b733e6f92",
     "grade": false,
     "grade_id": "Class3_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans3a = None\n",
    "ans3b = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans3a)\n",
    "print(f'length of ans3a: {ans3b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8712a39b7b4a917407551f34430bfbd1",
     "grade": true,
     "grade_id": "Class3_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6a16fb1b1be57e752c49ef60777e67ef",
     "grade": false,
     "grade_id": "Q4_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 4: Select the Desired Table\n",
    "\n",
    "Now that you’ve retrieved all the tables from the page, your task is to identify the one that contains the following entry:\n",
    "\n",
    "> **Contract Size: 10 GBP X Index Points**\n",
    "\n",
    "This information appears in the **FTSE (QFA) Contract Specifications** table.\n",
    "\n",
    "<img src=\"images/hk_qc_QFA_image_imp_pcba.png\" alt=\"Contracts Table\" />\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Manually inspect the tables in `ans3a` using indexing and `.prettify()` or `print(ans3a[i].text)` to identify which table contains the desired content.\n",
    "2. Once you’ve identified the correct index (e.g., `ans3a[5]`), assign that specific table to a new variable called `ans4`.\n",
    "\n",
    "```python\n",
    "# Replace the index below with the correct one after inspection\n",
    "ans4 = ans3a[??]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d094a36e260006fa21fd03ba9f7772af",
     "grade": false,
     "grade_id": "Class4_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "ans4 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c6c505a24ff509922741a93589d314a0",
     "grade": true,
     "grade_id": "Class4_Tests",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "59a280c11fde6481bcf990a86ec79be9",
     "grade": false,
     "grade_id": "Q5_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 5: Extract All Rows from the FTSE (QFA) Contract Specifications Table\n",
    "\n",
    "Now that you've identified the table containing the contract information, your next task is to extract all the rows within this table.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Use the `.find_all('tr')` method on `ans4` (the table identified in Question 4) to get all the table rows.\n",
    "2. Assign the result (a list of `<tr>` tags) to a variable named `ans5a`.\n",
    "3. Count the number of rows and assign it to a variable named `ans5b`.\n",
    "\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "ans4.find_all('tr')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2abc2f4ce6c2fb7acc0d525060404fc",
     "grade": false,
     "grade_id": "Class5_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans5a = None\n",
    "ans5b = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans5a)\n",
    "print(f'Length of ans5a: {ans5b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75b6e1fdbe304bbdd3090f5a74543126",
     "grade": true,
     "grade_id": "Class5_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "30ca8ea1b4b3c1a0ab368a1300fd6b32",
     "grade": false,
     "grade_id": "Q6_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 6: Extract the Contract Size Value\n",
    "\n",
    "Now that you have extracted all the rows from the **FTSE (QFA) Contract Specifications** table, your task is to find specific row for **Contract Size**.\n",
    "\n",
    "The goal is to find the row containing the text `Contract Size:` and retrieve its value.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Inspect the rows in `ans5a` to locate the index of the row that contains the text **Contract Size**.\n",
    "2. Once you identify the correct row, assign it to a variable named `ans6`.\n",
    "\n",
    "```python\n",
    "ans6 = ans5a[???]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "017ab93d8a2e6a299b3fc4a069f6308a",
     "grade": false,
     "grade_id": "Class6_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans6 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cba371d833d26160bf8bcbab44da3deb",
     "grade": true,
     "grade_id": "Class6_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75686fc15ca752f6de1c03ebc945ef5b",
     "grade": false,
     "grade_id": "Q7_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 7: Retrieve the Contract Size Value from the Table Row\n",
    "\n",
    "Now that you've identified the correct row in the table, the final step is to extract the **Contract Size** value. This time, you need to look inside the **`<td>`** tags of the row containing the contract size information.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Use BeautifulSoup’s `.find_all('td')` method to find all **`<td>` tags** in the row containing the contract size information (stored in `ans6`).\n",
    "2. Extract the specific value/text (which should be in the `<td>` tag related to **Contract Size**) and assign it to `ans7`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dda66756cca0989ba3762444b4fa63ae",
     "grade": false,
     "grade_id": "Class7_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "ans7 = None\n",
    "ans7tds = ans6.find_all('td')\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(ans7.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ac6083e01d8f6c5a5983152e52970b5",
     "grade": true,
     "grade_id": "Class7_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "db241302362909817b801ad7bbcf1b67",
     "grade": false,
     "grade_id": "Q8_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 8: Implement Function to Retrieve All Hyperlinks\n",
    "\n",
    "For this part of the assignment, you need to retrieve all the hyperlinks on a webpage using BeautifulSoup. Your boss has asked you to implement the function **`get_all_urls(page)`**, which will return a list of all the hyperlinks found on the page.\n",
    "\n",
    "In this task, you will:\n",
    "1. Use **BeautifulSoup** to parse the HTML content of the page.\n",
    "2. Extract and return all hyperlinks (URLs) found within the page.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Implement the function **`get_all_urls(page)`** using BeautifulSoup to parse through the HTML content and find all the hyperlinks.\n",
    "2. Extract and return the **text** (.text) content of all hyperlinks (i.e., the visible clickable text between `<a>` and `</a>` tags).\n",
    "\n",
    "Here is the function signature and code template for you to complete:\n",
    "```python\n",
    "     def get_all_urls(page):\n",
    "        hyperlinksList = []\n",
    "        # Parse the page with BeautifulSoup\n",
    "        \n",
    "        # Find all the <a> tags (hyperlinks)\n",
    "        \n",
    "        # Loop through each link and add the visible text (.text) to hyperlinksList\n",
    "        \n",
    "        return hyperlinksList\n",
    "    \n",
    "```\n",
    "\n",
    "3. Use the provided `test_excerpt` to test your function once implemented.\n",
    "\n",
    "**Example Expected Output:**\n",
    "```\n",
    "['Archive', 'What If?', 'Blag', 'Store', 'About', '']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aa50f290200fbe30e0bb78853aa7a646",
     "grade": false,
     "grade_id": "ans8_excerpt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_excerpt = \"\"\"<!DOCTYPE html>\n",
    "                <html>\n",
    "                <body>\n",
    "                <div id=\"topContainer\">\n",
    "                <div id=\"topLeft\">\n",
    "                <ul>\n",
    "                <li><a href=\"/archive\">Archive</a></li>\n",
    "                <li><a href=\"http://what-if.xkcd.com\">What If?</a></li>\n",
    "                <li><a href=\"http://blag.xkcd.com\">Blag</a></li>\n",
    "                <li><a href=\"http://store.xkcd.com/\">Store</a></li>\n",
    "                <li><a rel=\"author\" href=\"/about\">About</a></li>\n",
    "                </ul>\n",
    "                </div>\n",
    "                <div id=\"topRight\">\n",
    "                <div id=\"masthead\">\n",
    "                <span><a href=\"/\"><img src=\"/s/0b7742.png\" alt=\"xkcd.com logo\" height=\"83\" width=\"185\"/></a></span>\n",
    "                <span id=\"slogan\">A webcomic of romance,<br/> sarcasm, math, and language.</span>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9d3d1ec91c351e61dc145f2176ee806e",
     "grade": false,
     "grade_id": "Class8_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "def get_all_urls(page):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "#Answer test\n",
    "get_all_urls(test_excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8bb4806ed95d2f9dc90752077e8a7a3d",
     "grade": true,
     "grade_id": "Class8_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "548bd73feb4411d83cce3fc198be0034",
     "grade": false,
     "grade_id": "Q9_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 9: Implement the `get_children()` Function\n",
    "\n",
    "In this task, you are required to implement the **`get_children(url)`** function, which will:\n",
    "1. Take a URL containing a web page as input.\n",
    "2. Retrieve the HTML content from the URL using the **`requests`** library.\n",
    "3. Call the previously implemented **`get_all_urls(page)`** function to extract and return all hyperlinks from the webpage.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. Implement the function **`get_children(url)`**, which will:\n",
    "   - Fetch the HTML content from the provided URL using the **`requests`** library.\n",
    "   - Use the **`get_all_urls(page)`** function to extract all hyperlinks from the HTML content.\n",
    "\n",
    "2. Use **`try` and `except`** to handle any exceptions that might occur when fetching the page.\n",
    "3. The function should return a list of URLs found on the web page.\n",
    "\n",
    "Here is the provided template for you to complete:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "def get_children(url):\n",
    "    try:\n",
    "        # Fetch the HTML content from the URL\n",
    "        page_source = None\n",
    "    except Exception:\n",
    "        # In case of an error, set the page source to an empty string\n",
    "        page_source = ''\n",
    "    \n",
    "    # Call get_all_urls to extract URLs from the page source\n",
    "    url_list = None\n",
    "    \n",
    "    return url_list\n",
    "```\n",
    "\n",
    "4. Once you’ve implemented the function, test it using:\n",
    "```python\n",
    "footsie_python = \"https://en.wikipedia.org/wiki/FTSE_100_Index\"\n",
    "child_list=get_children(footsie_python)\n",
    "print(child_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49c88e2c3b760db2cce3fd1c2ea2af31",
     "grade": false,
     "grade_id": "Class9_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "child_list=[]\n",
    "\n",
    "def get_children(url):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "footsie_python = \"https://en.wikipedia.org/wiki/FTSE_100_Index\"\n",
    "child_list=get_children(footsie_python)\n",
    "print(child_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4f6c022df978b89dce8de86cdd94993",
     "grade": true,
     "grade_id": "Class9_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "716978efbf8a0b84a89517ab90b388c1",
     "grade": false,
     "grade_id": "Q10_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "### Question 10: Implement the `crawl_web(start_url, max_depth)` Function\n",
    "\n",
    "In this task, you are required to implement the **`crawl_web(start_url, max_depth)`** function that performs a web crawl starting from a given URL and explores links recursively up to the specified maximum depth. You will use the previously implemented function **`get_children(url)`** to extract hyperlinks from each page.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "1. **Implement the `crawl_web(start_url, max_depth)` function**:\n",
    "   - This function performs a web crawl starting from the given `start_url`.\n",
    "   - It uses a **path-based approach**, maintaining a list of paths (URL sequences) to crawl.\n",
    "   - It explores new URLs only if the depth of the path is less than or equal to `max_depth`.\n",
    "   - For each visited page, it:\n",
    "     - Uses `get_children(url)` to retrieve all the hyperlinks on that page.\n",
    "     - Adds those child URLs to a graph dictionary where the key is the parent URL and the value is the list of children.\n",
    "     - Avoids revisiting already crawled pages.\n",
    "\n",
    "Here is the function structure:\n",
    "\n",
    "```python\n",
    "FTSE_websites = {}\n",
    "\n",
    "def crawl_web(start_url, max_depth):\n",
    "    # Initialize a list to keep track of already crawled URLs\n",
    "    crawled = []\n",
    "\n",
    "    # Initialize a dictionary to hold the structure of crawled pages\n",
    "    # Keys will be URLs, values will be lists of URLs found on those pages\n",
    "    graph = {}\n",
    "\n",
    "    # Initialize the list of paths to crawl, starting with the initial URL\n",
    "    # Each path is a list of URLs from the start to the current node\n",
    "    to_crawl = [[start_url]]\n",
    "\n",
    "    # Start the crawling loop\n",
    "    while to_crawl:\n",
    "        # Take the first path from the list (FIFO queue for BFS)\n",
    "        path = None\n",
    "\n",
    "        # If the path length exceeds max_depth, skip further crawling from here\n",
    "        if #condition here:\n",
    "            break\n",
    "\n",
    "        # Get the current URL to crawl (the last URL in the path)\n",
    "        url = path[-1]\n",
    "\n",
    "        # If this URL hasn't been crawled yet\n",
    "        if url not in crawled:\n",
    "            # Get all the children (linked URLs) of the current URL. Use get_children() method.\n",
    "            children = None\n",
    "\n",
    "            # Add the URL and its children to the graph\n",
    "            graph[url] = None \n",
    "\n",
    "            # Add new paths to to_crawl by extending the current path with each child\n",
    "            to_crawl.extend(...)\n",
    "\n",
    "    # Return the final graph of crawled pages and their links\n",
    "    return graph\n",
    "\n",
    "FTSE_websites = crawl_web(start_url=\"https://en.wikipedia.org/wiki/FTSE_100_Index\", max_depth=2)\n",
    "\n",
    "# Test output\n",
    "print(FTSE_websites)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Output\n",
    "\n",
    "- `FTSE_websites` will be a dictionary that maps each URL visited to a list of its direct hyperlinks (children).\n",
    "- The crawler visits pages to a maximum path length of `max_depth`, ensuring exploration stays within depth limits.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Structure\n",
    "\n",
    "If your crawler visits:\n",
    "\n",
    "- Depth 0: FTSE main page\n",
    "- Depth 1: Pages linked directly from FTSE page\n",
    "- Depth 2: Pages linked from those in depth 1\n",
    "\n",
    "The starting of your dictionary might look like:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'https://en.wikipedia.org/wiki/FTSE_100_Index': [\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2c5595aa7eb776e00ff8b7762b6fe035",
     "grade": false,
     "grade_id": "Class10_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "FTSE_websites={}\n",
    "\n",
    "def crawl_web(start_url, max_depth):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer test\n",
    "print(FTSE_websites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ae79c0231b6babc5977ad734c2917f0",
     "grade": true,
     "grade_id": "Class10_Test",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
