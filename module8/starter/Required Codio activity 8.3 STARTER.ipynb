{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d65d3c2a4bd8503b598ba871248e4d1a",
     "grade": false,
     "grade_id": "Introduction",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Required Codio activity: Web crawling in action\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this activity, you will perform **web crawling using the Breadth-First Search (BFS) algorithm**. You'll simulate crawling through a simplified HTML structure and extract links in a manner similar to how search engines index web pages.\n",
    "\n",
    "This task is designed to:\n",
    "- Strengthen your Python coding skills.\n",
    "- Reinforce your understanding of BFS.\n",
    "- Help you gain hands-on experience with HTML parsing using the **Beautiful Soup** library.\n",
    "\n",
    "As you proceed, the complexity of the tasks will increase. We recommend you run and test your code in each step before moving to the next one.\n",
    "\n",
    "> **Important:** All functions you write must match the expected signatures and return formats exactly, as automated tests will be used to assess your submission.\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Outcome\n",
    "\n",
    "By the end of this activity, you should be able to:\n",
    "\n",
    "- Implement the **Breadth-First Search** algorithm to crawl and extract information from an HTML page using the **Beautiful Soup** library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35afcbde969800f7aa93ba6cb37cf849",
     "grade": false,
     "grade_id": "Index",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "## Index:\n",
    "\n",
    "- [Question 1](#Question-1)\n",
    "- [Question 2](#Question-2)\n",
    "- [Question 3](#Question-3)\n",
    "- [Question 4](#Question-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2d71b460d6ee43582f677878e81eaf5",
     "grade": false,
     "grade_id": "agq_excerpt_desc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Setup: HTML Excerpt for Parsing\n",
    "\n",
    "Run the cell below to initialize `html_excerpt`, which contains an excerpt of HTML taken from [All Great Quotes – Literary Quotes](https://www.allgreatquotes.com/literary_quotes.shtml). You will use this throughout the activity to simulate a basic web crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7d36b0bf06d70e116070c748f6e6deb",
     "grade": false,
     "grade_id": "agq_excerpt",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Define html_excerpt for this activity\n",
    "\n",
    "html_excerpt = (\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<title>Literary Quotes</title>\n",
    "\n",
    "\n",
    "  AUTHORS by last name: <a href=\"/authors-a/\">A</a>&nbsp <a href=\"/\">B</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-c/\">C</a>&nbsp <a href=\"/authors-d/\">D</a>&nbsp <a href=\"/authors-e/\">E</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-f/\">F</a>&nbsp <a href=\"/authors-g/\">G</a>&nbsp <a href=\"/authors-h/\">H</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-i/\">I</a>&nbsp <a href=\"/authors-j/\">J</a>&nbsp <a href=\"/authors-k/\">K</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-l/\">L</a>&nbsp <a href=\"/authors-m/\">M</a>&nbsp <a href=\"/authors-n/\">N</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-o/\">O</a>&nbsp <a href=\"/authors-p/\">P</a>&nbsp <a href=\"/authors-q/\">Q</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-r/\">R</a>&nbsp <a href=\"/authors-s/\">S</a>&nbsp <a href=\"/authors-t/\">T</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-u/\">U</a>&nbsp <a href=\"/authors-v/\">V</a>&nbsp <a href=\"/authors-w/\">W</a>&nbsp \n",
    "\n",
    "  <a href=\"/authors-x/\">X</a>&nbsp <a href=\"/authors-y/\">Y</a>&nbsp <a href=\"/authors-z/\">Z</a><br>\n",
    "\n",
    "  <br>\n",
    "\n",
    "  <a href=\"/topics/motivational-quotes/\">Motivational</a> - <a href=\"/topics/love-quotes/\">Love</a> - <a href=\"/topics/funny-quotes/\">Funny</a> \n",
    "\n",
    "  - <a href=\"/topics/friendship-quotes/\">Friendship</a> - <a href=\"/topics/life-quotes/\">Life</a> \n",
    "\n",
    "  - <a href=\"/topics/family/\">Family</a> - <a href=\"/quote-authors/\">Authors</a> - <a href=\"/quote-topics/\">Topics</a><br>\n",
    "\n",
    "  <br>\n",
    "</html>\"\"\"\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "88fd50cf604ee0b47a369fe50f7dccf1",
     "grade": false,
     "grade_id": "Q1_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "---\n",
    "\n",
    "### Question 1: Extracting the Next URL from HTML\n",
    "\n",
    "In this task, you will define a function `get_next_url(page)` that extracts the **next hyperlink** (i.e., a string between the first `<a href=\"...\">`) from the given HTML page string.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. Complete the following function:\n",
    "\n",
    "```python\n",
    "def get_next_url(page):\n",
    "    start_link = page.find(None)   # Find the starting point of the first anchor tag\n",
    "    start_quote = page.find('\"', None)  # Find the first quote after the anchor\n",
    "    end_quote = page.find('\"', None)  # Find the closing quote\n",
    "    url = page[start_quote + 1: end_quote]  # Extract the URL between quotes\n",
    "    return url, end_quote\n",
    "```\n",
    "\n",
    "2. What the function does:\n",
    "    - Finds the index of the first `<a href=` in the string and stores it in `start_link`.\n",
    "    - Finds the position of the first double quote (`\"`) after `start_link`, which marks the beginning of the URL.\n",
    "    - Finds the next double quote (`\"`) after `start_quote`, which marks the end of the URL.\n",
    "    - Extracts and returns the URL string between the quotes.\n",
    "    - Also returns `end_quote`, the index of the closing quote, to track where parsing should continue.\n",
    "\n",
    "\n",
    "3. **Test your function** by calling it on `html_excerpt` (initialized earlier):\n",
    "\n",
    "```python\n",
    "next_url, end_quote = get_next_url(html_excerpt)\n",
    "print(next_url)\n",
    "print(end_quote)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Expected Output:\n",
    "```\n",
    "/authors-a/\n",
    "107\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Review the documentation for the [`str.find()` method](https://www.programiz.com/python-programming/methods/string/find) in Python if you're unsure how it works.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "35e326c07b17ad8d9d7b96e5ee3e8690",
     "grade": false,
     "grade_id": "Class1_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_next_url(page):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "#Answer test\n",
    "next_url, end_quote = get_next_url(html_excerpt)\n",
    "print(next_url)\n",
    "print(end_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5baa5621af6f9e461cae29b579e9a2a1",
     "grade": true,
     "grade_id": "Class1_Tests",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "418809f25b78c007e35a2c0bc2055bc6",
     "grade": false,
     "grade_id": "Q2_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "---\n",
    "\n",
    "### Question 2: Extracting All URLs\n",
    "\n",
    "In this task, you will complete a function `get_all_urls(page)` that extracts **all hyperlinks** (i.e., values from `<a href=\"...\">`) from a given HTML string. You will use the `get_next_url()` function you implemented in **Question 1**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Complete the following function definition using the template and comments as guidance:\n",
    "```python\n",
    "        def get_all_urls(page):\n",
    "            url_list = []\n",
    "            while True:\n",
    "                url, end_quote = None  # Call get_next_url here\n",
    "                if url:\n",
    "                    url_list.append(None)  # Add the extracted url to the list\n",
    "                    page = page[None:]  # Slice the page string to continue parsing\n",
    "                else:\n",
    "                    break\n",
    "            return None  # Return the final list of URLs\n",
    "```\n",
    "\n",
    "- This function takes a string of HTML content and returns a list of all URLs found.\n",
    "- The loop should continue until no more URLs are found by `get_next_url`.\n",
    "- Use the `end_quote` index to slice the remaining string after each found URL.\n",
    "\n",
    "---\n",
    "\n",
    "#### Test Your Function\n",
    "\n",
    "Call your function using the provided `html_excerpt` string:\n",
    "\n",
    "```python\n",
    "url_list = get_all_urls(html_excerpt)\n",
    "print(url_list)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Expected Output\n",
    "\n",
    "```python\n",
    "['/authors-a/', '/', '/authors-c/', '/authors-d/', '/authors-e/', '/authors-f/', '/authors-g/', '/authors-h/', '/authors-i/', '/authors-j/', '/authors-k/', '/authors-l/', '/authors-m/', '/authors-n/', '/authors-o/', '/authors-p/', '/authors-q/', '/authors-r/', '/authors-s/', '/authors-t/', '/authors-u/', '/authors-v/', '/authors-w/', '/authors-x/', '/authors-y/', '/authors-z/', '/topics/motivational-quotes/', '/topics/love-quotes/', '/topics/funny-quotes/', '/topics/friendship-quotes/', '/topics/life-quotes/', '/topics/family/', '/quote-authors/', '/quote-topics/']\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: The `get_next_url()` function should return a tuple with the next URL and the position of the end quote. Use both values to process the next segment of HTML in the loop.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d65e808fae5cf5a432772df009792314",
     "grade": false,
     "grade_id": "Class2_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_all_urls(page):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "#Answer test\n",
    "all_url_list = get_all_urls(html_excerpt)\n",
    "print(all_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b59cfe33cd94e4d62af3cb984f50708",
     "grade": true,
     "grade_id": "Class2_Tests",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "341c8d02930d6cfd220dd23c637b6e67",
     "grade": false,
     "grade_id": "Q4_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "---\n",
    "\n",
    "### Question 3: Getting All Links from a Live Web Page\n",
    "\n",
    "In this task, you will implement a function `get_children(url)` that fetches a live web page using `requests`, extracts its HTML, and returns all the hyperlinks it contains.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Complete the following function definition using the template and comments as guidance:\n",
    "```python\n",
    "        def get_children(url):\n",
    "            try:\n",
    "                page_source = None  # Use requests.get(url).text to fetch the page content\n",
    "            except Exception:\n",
    "                page_source = ''  # Fallback in case of an error (e.g., bad URL or connection issue)\n",
    "            url_list = None  # Call get_all_urls(page_source) to extract URLs from the HTML\n",
    "            return url_list\n",
    "```\n",
    "- This function should:\n",
    "  - Use the `requests` library to fetch the web page contents.\n",
    "  - Use the `get_all_urls` function (from Question 2) to extract all the hyperlinks from the HTML.\n",
    "  - Return the list of hyperlinks.\n",
    "\n",
    "---\n",
    "\n",
    "####  Test Your Function\n",
    "\n",
    "Use the URL below to test the function:\n",
    "\n",
    "```python\n",
    "url = \"https://www.allgreatquotes.com/literary_quotes.shtml\"\n",
    "children = get_children(url)\n",
    "print(children)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Hint**: Don't forget to `import requests` if it hasn’t been already. Make sure your earlier `get_all_urls` function is working correctly before testing this function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c2cf6a7509aee2afebef74fe37049cf8",
     "grade": false,
     "grade_id": "Class4_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_children(url):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer check\n",
    "agq_literaryQuotes = 'https://www.allgreatquotes.com/literary_quotes.shtml'\n",
    "child_list=get_children(agq_literaryQuotes)\n",
    "print(child_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b6dab6ce4f5eff8b6af3961a79e2b2ea",
     "grade": true,
     "grade_id": "Class4_Tests",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "db74ce721e80cbdb8d3ebd1e3c7efc53",
     "grade": false,
     "grade_id": "Q5_Description",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "###### [Back to top](#Index:) \n",
    "\n",
    "---\n",
    "\n",
    "### Question 4: Web Crawler using Breadth-First Search (BFS)\n",
    "\n",
    "Now it’s time to put it all together by implementing the BFS algorithm to crawl a website and collect hyperlinks.\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "- Complete the function definition for `crawl_web(start_url, max_depth)` using the template below:\n",
    "```python\n",
    "        def crawl_web(start_url, max_depth):\n",
    "            \"\"\"\n",
    "            Returns a dictionary of all visited URLs and their children\n",
    "            using a breadth-first search strategy.\n",
    "            \"\"\"\n",
    "            crawled = []\n",
    "            hyperlinksDict = {}\n",
    "            to_crawl = [[start_url]]  # A queue of paths (BFS)\n",
    "            \n",
    "            while to_crawl:\n",
    "                path = to_crawl.pop(0)\n",
    "                if len(path) > max_depth:\n",
    "                    break\n",
    "                url = path[-1]\n",
    "                \n",
    "                if url not in hyperlinksDict:\n",
    "                    children = None  # Call get_children(url)\n",
    "                    hyperlinksDict[None] = None  # Store children for the current URL\n",
    "                    to_crawl.extend([path + [child] for child in children])  # Add new paths to queue\n",
    "\n",
    "            return None  # Return the dictionary of hyperlinks\n",
    "```\n",
    "- The `start_url` parameter is the entry point for the crawler.\n",
    "- The `max_depth` controls how deep the crawler should go.\n",
    "- You should store each URL and the list of its child hyperlinks in a dictionary (`hyperlinksDict`).\n",
    "- You should also prevent revisiting URLs.\n",
    "\n",
    "---\n",
    "\n",
    "#### Test Your Function\n",
    "\n",
    "Run the function with the following parameters:\n",
    "\n",
    "```python\n",
    "result = crawl_web('https://www.allgreatquotes.com/literary_quotes.shtml', 2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Hints**:\n",
    "- Use the previously defined `get_children()` to get hyperlinks from a URL.\n",
    "- Make sure to replace `None` placeholders with actual logic.\n",
    "- Avoid revisiting pages by keeping track of visited URLs in the dictionary keys.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5f8736f3cca36171d9fac23137832f2e",
     "grade": false,
     "grade_id": "Class5_Ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def crawl_web(start_url, max_depth):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "# Answer check\n",
    "agq_websites = crawl_web(start_url='https://www.allgreatquotes.com/literary_quotes.shtml', max_depth=2)\n",
    "print(agq_websites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1fed11d8f3b150b9dd08571734f4c7c4",
     "grade": true,
     "grade_id": "Class5_Test",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
